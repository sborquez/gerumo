import pandas as pd
import numpy as np

from gerumo.data.io import load_dataset

def load_hillas_dataset(events_csv: str, telescopes_csv: str, results_csv: str, hillas_csv: str) -> pd.DataFrame:
    """
    Perform simple aggegation to targe columns.

    Parameters
    ==========
    events_csv : `str`
        Events dataset
    telescopes_csv : `str`
        Telescopes dataset
    results_csv: `str`
        The hillas reconstruction .csv generated by `baseline.reconstructor.Reconstructor`
    hillas_csv: `str`
        The hillas parameters .csv saved by `baseline.reconstructor.Reconstructor`
    Returns
    =======
    `pd.DataFrame`
        Dataset with event information, hillas reconstructions results and parameters.
    """

    hillas = pd.read_csv(hillas_csv)
    results = pd.read_csv(results_csv)

    results = results.drop(labels=["core_x", "core_y", "alt", "az", "mc_energy"], axis="columns")

    dataset = load_dataset(events_csv, telescopes_csv)

    hillas.columns = [f"hillas_{it}" if it in ["x", "y"] else it for it in hillas.columns]

    results_hillas = pd.merge(results, hillas, on=["event_unique_id"], validate="1:m")
    full = pd.merge(dataset, results_hillas, on=["event_unique_id", "type", "observation_indice"], validate="1:1")

    return full


def aggregate_hillas_dataset(dataset: pd.DataFrame):
    dataset.loc[:,"log10_intensity"] = np.log10(dataset["intensity"])
    
    core_x = dataset["pred_core_x"]
    x = dataset["x"]

    core_y = dataset["pred_core_y"]
    y = dataset["y"]

    impact = np.sqrt((core_x - x) ** 2 + (core_y + y) ** 2)
    dataset.loc[:,"log10_impact"] = np.log10(impact)

    return dataset
